import yfinance as yf
import pandas as pd
import datetime
import time
from tqdm import tqdm
import logging
import requests
import os
from io import StringIO

# å¼•å…¥é…ç½®
# ç¡®ä¿ä½ çš„ src/config.py é‡Œå·²ç»æœ‰äº† SP500_LIMIT, SP600_LIMIT è¿™äº›å®šä¹‰
from src.config import DATA_DIR, ETF_BLOCKLIST, PROXY_URL, DB_PATH, SP500_LIMIT, SP600_LIMIT, SP400_LIMIT, NASDAQ_LIMIT
from src.data_manager import DataManager

# è¯¦ç»†çš„æ—¥å¿—æ ¼å¼
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("InitData")

def get_tickers_from_wiki(url, name):
    """ã€çˆ¬è™«ã€‘ä»ç»´åŸºç™¾ç§‘è·å–ä»£ç  (ç¨³å¥ç‰ˆ)"""
    logger.info(f"ğŸŒ Crawling {name} from Wikipedia...")
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) "
                      "Chrome/91.0.4472.124 Safari/537.36"
    }
    
    proxies = {
        "http": os.environ.get("HTTP_PROXY", PROXY_URL),
        "https": os.environ.get("HTTPS_PROXY", PROXY_URL)
    }
    
    try:
        response = requests.get(url, headers=headers, proxies=proxies, timeout=20)
        response.raise_for_status()
        
        tables = pd.read_html(StringIO(response.text))
        df = tables[0]
        
        col_name = 'Symbol' if 'Symbol' in df.columns else 'Ticker symbol'
        if col_name not in df.columns:
            col_name = df.columns[0]
            
        raw_tickers = df[col_name].astype(str).tolist()
        
        cleaned_tickers = []
        garbage_list = [
            'CONSTITUENTS', 'EXCHANGES', 'SYMBOL', 'TICKER', 'SECURITY', 'COMPANY', 'GICS SECTOR', 
            'FOUNDATION', 'OPERATOR', 'TYPE', 'WEBSITE'
        ]
        
        for t in raw_tickers:
            # 1. Basic Cleaning
            t = t.replace('.', '-').replace('$', '').strip()
            
            # 2. Garbage Filter
            if t.upper() in garbage_list: continue
            if len(t) > 5 and not t.isalpha(): continue # Skip weird long strings
            if not t: continue
            
            cleaned_tickers.append(t)
            
        tickers = cleaned_tickers
        
        logger.info(f"âœ… Successfully fetched {len(tickers)} tickers for {name}")
        return tickers
        
    except Exception as e:
        logger.error(f"âŒ Failed to scrape {name}: {e}")
        return []

def process_single_stock(ticker, db, last_update_date=None, is_benchmark=False):
    """
    ã€ä¸‹è½½æ ¸å¿ƒã€‘å¤„ç†å•ä¸ªè‚¡ç¥¨
    å‡çº§ç‚¹ï¼šæ··åˆä¸‹è½½å¹´åº¦(Financials)å’Œå­£åº¦(Quarterly)è´¢æŠ¥ï¼Œè§£å†³å†å²æ•°æ®ä¸è¶³é—®é¢˜
    """
    try:
        # ==========================================
        # A. æ™ºèƒ½è·³è¿‡åˆ¤æ–­ (Smart Skip)
        # ==========================================
        # ä¸ºäº†ä¿®å¤æ•°æ®ç¼ºå¤±ï¼Œå»ºè®®ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶å…ˆæŠŠè¿™é‡Œæ”¹çŸ­ï¼Œæˆ–è€…ç›´æ¥åˆ æ‰åº“é‡è·‘
        # è¿™é‡Œä¿ç•™ 10y çš„é•¿åº¦ä»¥ç¡®ä¿è¦†ç›– 2021 å¹´çš„å›æµ‹éœ€æ±‚
        download_period = "10y" 
        start_date = None
        
        if last_update_date:
            last_dt = datetime.datetime.strptime(last_update_date, '%Y-%m-%d')
            today_dt = datetime.datetime.now()
            days_diff = (today_dt - last_dt).days
            
            # æé€Ÿæ£€æŸ¥
            if days_diff < 1:
                return 0 
            
            # å‘¨æœ«è±å…
            if today_dt.weekday() >= 5 and days_diff <= 2: 
                return 0

            # å¢é‡æ›´æ–°
            next_day = last_dt + datetime.timedelta(days=1)
            # å¦‚æœä¸‹ä¸€å¤©å°±æ˜¯ä»Šå¤©ï¼Œä¸”è¿˜æ²¡æ”¶ç›˜(ç®€å•åˆ¤æ–­)ï¼Œå¯èƒ½å–ä¸åˆ°æ•°æ®ï¼Œå»ºè®®è·³è¿‡
            if next_day.date() == today_dt.date():
                 # ç®€å•ç­–ç•¥ï¼šå¦‚æœè¿˜æ²¡è¿‡ä¸‹åˆ5ç‚¹(ç¾è‚¡æ”¶ç›˜)ï¼Œå°±ä¸å¼ºæ±‚æ›´æ–°ä»Šå¤©çš„æ•°æ®
                 if today_dt.hour < 17:
                     return 0

            start_date = next_day.strftime('%Y-%m-%d')
            download_period = None 

        # Santize ticker
        original_ticker = ticker
        ticker = ticker.replace('$', '').strip() 
        if original_ticker != ticker:
            logger.info(f"ğŸ”§ Sanitized ticker: {original_ticker} -> {ticker}")

        # ==========================================
        # B. ä»·æ ¼ä¸‹è½½ (Price Data)
        # ==========================================
        # logger.debug(f"Processing: {ticker}")
        obj = yf.Ticker(ticker)

        # ã€æ–°å¢ä¿®å¤ã€‘ æ£€æŸ¥æ‹†è‚¡ (Splits)
        # å¦‚æœä¸Šæ¬¡æ›´æ–°åå‘ç”Ÿäº†æ‹†è‚¡ï¼Œå¿…é¡»å…¨é‡é‡ä¸‹ï¼Œå¦åˆ™ä»·æ ¼ä¸è¿ç»­
        if start_date:
            try:
                splits = obj.splits
                if not splits.empty:
                    # æ‰¾åˆ°æœ€è¿‘ä¸€æ¬¡æ‹†è‚¡æ—¶é—´
                    last_split_date = splits.index.max().to_pydatetime()
                    last_db_date = datetime.datetime.strptime(last_update_date, '%Y-%m-%d')
                    
                    # å¦‚æœæ‹†è‚¡å‘ç”Ÿåœ¨ä¸Šæ¬¡æ›´æ–°ä¹‹åï¼Œæˆ–è€…å°±æ˜¯åŒä¸€å¤©ï¼Œå¼ºåˆ¶é‡è·‘
                    if last_split_date >= last_db_date:
                        logger.info(f"ğŸ”„ Split detected for {ticker} on {last_split_date.date()}. Forcing full redownload.")
                        start_date = None
                        download_period = "10y"
            except Exception:
                pass # è·å–æ‹†è‚¡æ•°æ®å¤±è´¥ï¼Œå®‰å…¨èµ·è§æŒ‰åŸè®¡åˆ’è·‘ (æˆ–è€…ä¹Ÿå¯ä»¥é€‰æ‹©å¼ºåˆ¶é‡è·‘ï¼Œè¿™é‡Œå…ˆä¿å®ˆ)
        
        if start_date:
            hist = obj.history(start=start_date, auto_adjust=True)
        else:
            hist = obj.history(period=download_period, auto_adjust=True)
            
        if not hist.empty:
            if hist.index.tz is not None:
                hist.index = hist.index.tz_localize(None)
            
            records = []
            for d, row in hist.iterrows():
                records.append((d.strftime('%Y-%m-%d'), ticker, row['Close'], row['Volume']))
            db.save_prices(records)
        
        # Benchmark æˆ– å¢é‡æ›´æ–°æ— æ•°æ®æ—¶ï¼Œç›´æ¥è¿”å›
        if is_benchmark: return 1
        if start_date and hist.empty: return 1

        # ==========================================
        # C. è´¢æŠ¥ä¸‹è½½ (Fundamentals) - æ··åˆå¢å¼ºç‰ˆ
        # ==========================================
        # åŒæ—¶æŠ“å– .quarterly_financials (çµæ•ï¼Œè¿‘1å¹´) å’Œ .financials (å¹´åº¦ï¼Œè¿‘4å¹´)
        
        q_fin = obj.quarterly_financials
        q_bs = obj.quarterly_balance_sheet
        a_fin = obj.financials
        a_bs = obj.balance_sheet
        
        # æ²¡æœ‰ä»»ä½•æ•°æ®åˆ™é€€å‡º
        if (q_fin.empty and a_fin.empty) or (q_bs.empty and a_bs.empty):
            return -1

        # è¾…åŠ©å‡½æ•°ï¼šè§£ææ•°æ®æ¡†å¹¶æå–ä¸º list of tuples
        def extract_data(fin_df, bs_df):
            if fin_df.empty or bs_df.empty: return []
            
            common_dates = fin_df.columns.intersection(bs_df.columns)
            shares = obj.info.get('sharesOutstanding')
            
            if not shares or len(common_dates) == 0: return []

            recs = []
            for date in common_dates:
                try:
                    # æå– Net Income å’Œ Revenueï¼Œå®¹é”™å¤„ç†
                    ni = fin_df.loc['Net Income', date] if 'Net Income' in fin_df.index else 0
                    rev = fin_df.loc['Total Revenue', date] if 'Total Revenue' in fin_df.index else 0
                    
                    # æƒç›Šå­—æ®µå¯èƒ½æœ‰å˜ç§
                    eq = 0
                    for k in ['Stockholders Equity', 'Total Stockholder Equity', 'Total Equity']:
                        if k in bs_df.index:
                            eq = bs_df.loc[k, date]
                            break

                    # [FF5æ–°å¢] æ€»èµ„äº§ (ç”¨äº CMA)
                    assets = bs_df.loc['Total Assets', date] if 'Total Assets' in bs_df.index else 0
                    
                    # [FF5æ–°å¢] è¥ä¸šåˆ©æ¶¦ (ç”¨äº RMW)
                    op_inc = 0
                    for k in ['Operating Income', 'Operating Profit', 'EBIT']:
                        if k in fin_df.index:
                            op_inc = fin_df.loc[k, date]
                            break
                    
                    # 60å¤©å‰è§†åå·®é˜²æŠ¤ (Pit-in-Time Lag)
                    # å‡è®¾è´¢æŠ¥å‘å¸ƒæ—¥ = æŠ¥å‘ŠæœŸ + 60å¤©
                    eff_date = date + datetime.timedelta(days=60)
                    if eff_date > datetime.datetime.now(): continue
                    
                    recs.append((
                        eff_date.strftime('%Y-%m-%d'), # æ•°æ®å¯ç”¨æ—¥æœŸ (ç”¨äºå›æµ‹)
                        ticker, 
                        float(ni), float(eq), float(rev), float(shares), 
                        date.strftime('%Y-%m-%d'),      # åŸå§‹æŠ¥å‘ŠæœŸ
                        float(assets), float(op_inc)    # [FF5æ–°å¢]
                    ))
                except Exception:
                    continue
            return recs

        # åˆ†åˆ«æå–
        q_records = extract_data(q_fin, q_bs)
        a_records = extract_data(a_fin, a_bs)
        
        # åˆå¹¶ (REPLACE INTO ä¼šè‡ªåŠ¨å»é‡)
        all_records = q_records + a_records
        
        if all_records:
            db.save_fundamentals(all_records)
            return 1 # æ›´æ–°æˆåŠŸ

    except Exception:
        return -1

    return 1

def main():
    db = DataManager()
    
    print("\n" + "="*60)
    print("ğŸš€ QML Reborn: Robust Update Mode (Hybrid Fundamentals)")
    print("ğŸ“¢ Version: With Ticker Sanitization Fix (No $)")
    print("="*60)

    # 1. æ‰«æç°çŠ¶
    print("ğŸ“Š Scanning existing database...")
    existing_map = db.get_latest_dates_map()
    print(f"âœ… Found {len(existing_map)} stocks already in DB.")

    # 2. å¼ºåˆ¶æ£€æŸ¥ Benchmark (SPY)
    print("\n-------- Checking Benchmark (SPY) --------")
    spy_status = process_single_stock('SPY', db, existing_map.get('SPY'), is_benchmark=True)
    if spy_status == 0:
        print("â­ï¸  SPY is up-to-date (Skipped).")
    elif spy_status == 1:
        print("âœ… SPY Data Updated.")
    else:
        print("âš ï¸ SPY Update Failed (Check Network).")

    # 3. æŠ“å–æ­£è‚¡åå•
    sp500 = get_tickers_from_wiki("https://en.wikipedia.org/wiki/List_of_S%26P_500_companies", "S&P 500")
    if SP500_LIMIT is not None:
        print(f"ğŸš§ Test Mode: Limiting S&P 500 to first {SP500_LIMIT} stocks.")
        sp500 = sp500[:SP500_LIMIT]

    sp600 = get_tickers_from_wiki("https://en.wikipedia.org/wiki/List_of_S%26P_600_companies", "S&P 600")
    if SP600_LIMIT is not None:
        print(f"ğŸš§ Test Mode: Limiting S&P 600 to first {SP600_LIMIT} stocks.")
        sp600 = sp600[:SP600_LIMIT]

    # [æ–°å¢] S&P 400 MidCap
    sp400 = get_tickers_from_wiki("https://en.wikipedia.org/wiki/List_of_S%26P_400_companies", "S&P 400")
    if SP400_LIMIT is not None:
        print(f"ğŸš§ Test Mode: Limiting S&P 400 to first {SP400_LIMIT} stocks.")
        sp400 = sp400[:SP400_LIMIT]

    # [æ–°å¢] Nasdaq 100
    nasdaq = get_tickers_from_wiki("https://en.wikipedia.org/wiki/Nasdaq-100", "Nasdaq 100")
    if NASDAQ_LIMIT is not None:
        print(f"ğŸš§ Test Mode: Limiting Nasdaq 100 to first {NASDAQ_LIMIT} stocks.")
        nasdaq = nasdaq[:NASDAQ_LIMIT]
    
    full_list = sorted(list(set(sp500 + sp600 + sp400 + nasdaq)))
    final_list = [t for t in full_list if t not in ETF_BLOCKLIST]
    
    print(f"\nğŸ¯ Total Targets: {len(final_list)} stocks")
    print("-" * 60)
    
    # 4. æ‰¹é‡æ‰§è¡Œ
    counts = {'Skip':0, 'Upd':0, 'Fail':0}
    pbar = tqdm(final_list, unit="stock")
    
    for i, ticker in enumerate(pbar):
        last_date = existing_map.get(ticker)
        
        status = process_single_stock(ticker, db, last_update_date=last_date)
        
        if status == 0: counts['Skip'] += 1
        elif status == 1: counts['Upd'] += 1
        else: counts['Fail'] += 1
        
        pbar.set_postfix(counts)
        
        # åŠ¨æ€é™æµ
        if status == 1:
            time.sleep(0.05) 
            if counts['Upd'] % 100 == 0:
                time.sleep(0.5)

    print("\n" + "="*60)
    print("âœ… PROCESS COMPLETED!")
    print(f"   â­ï¸  Skipped (Fresh):    {counts['Skip']}")
    print(f"   â¬‡ï¸  Downloaded (New):   {counts['Upd']}")
    print(f"   âš ï¸  Failed/Error:       {counts['Fail']}")
    print("="*60)

if __name__ == "__main__":
    main()